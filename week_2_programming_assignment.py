# -*- coding: utf-8 -*-
"""Week 2 programming assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WGqO3cmPr5eZAJDbKQJTPd_Thr2VP4fK
"""

from google.colab import drive
drive.mount('gdrive')

# Import packages
import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# MNIST data
mnist_data = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()

# Scale data
def scale_mnist_data(train_images, test_images):
  train_images = train_images / 255.
  test_images = test_images / 255.
  return (train_images, test_images)

train_scaled_images, test_scaled_images = scale_mnist_data(train_images, test_images)

# Add a dummy channel dimension
train_scaled_images = train_scaled_images[..., np.newaxis]
test_scaled_images = test_scaled_images[..., np.newaxis]

# Model
def get_model(input_shape):
  from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

  model = tf.keras.models.Sequential([
      Conv2D(8, (3,3), padding="SAME", activation="relu", input_shape=input_shape),
      MaxPooling2D((2,2)),
      Flatten(),
      Dense(64, activation="relu"),
      Dense(64, activation="relu"),
      Dense(10, activation="softmax")
  ])
  return model

model = get_model(train_scaled_images[0].shape)
model.summary()

# Compile the model
def compile_model(model):
  opt = tf.keras.optimizers.Adam()
  loss = tf.keras.losses.SparseCategoricalCrossentropy()
  acc = tf.keras.metrics.SparseCategoricalAccuracy()

  compile = model.compile(optimizer=opt, loss=loss, metrics=[acc])

  return compile

compile_model(model)

# Fit the model
def train_model(model, train_scaled_images, train_labels):
  history = model.fit(train_scaled_images, train_labels, epochs=5)

  return history

history = train_model(model, train_scaled_images, train_labels)

# Import history as a dataframe
frame = pd.DataFrame(history.history)
frame.head()

# Graph accuracy vs epochs
acc_plot = frame.plot(y="sparse_categorical_accuracy", title="Accuracy vs Epochs", legend=False)
acc_plot.set(xlabel="Epochs", ylabel="Accuracy")

# Graph loss vs epochs
acc_plot = frame.plot(y="loss", title = "Loss vs Epochs",legend=False)
acc_plot.set(xlabel="Epochs", ylabel="Loss")

# Evaluate the model
def evaluate_model(model, test_scaled_images, test_labels):
  evaluate = model.evaluate(test_scaled_images, test_labels, verbose=2)
  return evaluate

test_loss, test_accuracy = evaluate_model(model, test_scaled_images, test_labels)
print(f"Test loss: {test_loss}")
print(f"Test accuracy: {test_accuracy}")

# Model predictions
num_test_images = test_scaled_images.shape[0]

random_inx = np.random.choice(num_test_images, 4)
random_test_images = test_scaled_images[random_inx, ...]
random_test_labels = test_labels[random_inx, ...]

predictions = model.predict(random_test_images)

fig, axes = plt.subplots(4, 2, figsize=(16, 12))
fig.subplots_adjust(hspace=0.4, wspace=-0.2)

for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):
    axes[i, 0].imshow(np.squeeze(image))
    axes[i, 0].get_xaxis().set_visible(False)
    axes[i, 0].get_yaxis().set_visible(False)
    axes[i, 0].text(10., -1.5, f'Digit {label}')
    axes[i, 1].bar(np.arange(len(prediction)), prediction)
    axes[i, 1].set_xticks(np.arange(len(prediction)))
    axes[i, 1].set_title(f"Categorical distribution. Model prediction: {np.argmax(prediction)}")

plt.show()